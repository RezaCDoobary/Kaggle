{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial key points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training of the facial key points dataset is performed here, we select a basic CNN model and consider two basic metric changes - \n",
    "* 1 The preoprocessing, there are NaN's in the dataset - an investigation of three choices is employed\n",
    "    * Forward fill\n",
    "    * Fill with average of column (constant)\n",
    "    * Fill with a simple fitted guassian distribution\n",
    "\n",
    "* 2 The consideration of a non-CNN model and a full CNN model.\n",
    "    * It makes sense to benchmark with a non-convoluted model, since this is a simpler model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 . Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import gc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Opening data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_eye_center_x              10\n",
       "left_eye_center_y              10\n",
       "right_eye_center_x             13\n",
       "right_eye_center_y             13\n",
       "left_eye_inner_corner_x      4778\n",
       "left_eye_inner_corner_y      4778\n",
       "left_eye_outer_corner_x      4782\n",
       "left_eye_outer_corner_y      4782\n",
       "right_eye_inner_corner_x     4781\n",
       "right_eye_inner_corner_y     4781\n",
       "right_eye_outer_corner_x     4781\n",
       "right_eye_outer_corner_y     4781\n",
       "left_eyebrow_inner_end_x     4779\n",
       "left_eyebrow_inner_end_y     4779\n",
       "left_eyebrow_outer_end_x     4824\n",
       "left_eyebrow_outer_end_y     4824\n",
       "right_eyebrow_inner_end_x    4779\n",
       "right_eyebrow_inner_end_y    4779\n",
       "right_eyebrow_outer_end_x    4813\n",
       "right_eyebrow_outer_end_y    4813\n",
       "mouth_left_corner_x          4780\n",
       "mouth_left_corner_y          4780\n",
       "mouth_right_corner_x         4779\n",
       "mouth_right_corner_y         4779\n",
       "mouth_center_top_lip_x       4774\n",
       "mouth_center_top_lip_y       4774\n",
       "mouth_center_bottom_lip_x      33\n",
       "mouth_center_bottom_lip_y      33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/facial-keypoints-detection/training/training.csv')\n",
    "#null values:\n",
    "null = df.isnull().sum()\n",
    "null = null[null!=0]\n",
    "null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there a NaN values in the dataset, we now consider the different preoprocessing operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fillNaN(df_series, method):\n",
    "    \"\"\"\n",
    "    NaN filling method.\n",
    "    Input:\n",
    "        df_series [pandas.core.series.Series] : A pandas series type with NaN to be filled in.\n",
    "        method [string] : A string valued method to identify how the NaN handling should take place.\n",
    "    Output:\n",
    "        None, the NaN handling is performed in-place\n",
    "    \"\"\"\n",
    "    if method == \"forwardFill\":\n",
    "        df_series = df_series.fillna(method='ffill')\n",
    "    elif method == \"constantMean\":\n",
    "        mean = df_series.mean()\n",
    "        df_series = df_series.fillna(mean)\n",
    "    elif method == \"sampleDist\":\n",
    "        mean = df_series.mean()\n",
    "        std = df_series.std()\n",
    "        df_series = df_series.fillna(pd.Series(np.random.normal(mean, std, len(df_series))))\n",
    "    else:\n",
    "        raise ValueError(\"Method not identified : must be in forwardFill, constantMean or sampleDist\")\n",
    "    \n",
    "    return df_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a preprocess dictionary encapsulating all the data\n",
    "data_processing = {}\n",
    "data_processing['forwardFill'] = df.copy()\n",
    "data_processing['constantMean'] = df.copy()\n",
    "data_processing['sampleDist'] = df.copy()\n",
    "\n",
    "for key in data_processing.keys():\n",
    "    temp_df = data_processing[key]\n",
    "    for null_keys in null.keys():\n",
    "        data_processing[key][null_keys] = fillNaN(data_processing[key][null_keys], key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_images = df['Image'].map(lambda x : list(map(int,x.split(' '))))\n",
    "\n",
    "#Normalise the image data\n",
    "df_images = df_images.map(lambda x: list((np.array(x) - np.array(x).mean())/ np.array(x).std()))\n",
    "\n",
    "#delete the image columns from the output data\n",
    "for key in data_processing.keys():\n",
    "    del data_processing[key]['Image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So so far we have the following data:\n",
    "* A dictionary of dataframes dictated by the NaN handling method : data_processing\n",
    "* The corresponding images (dataframe) which have been normalised : df_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set up train-validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two classes :\n",
    "* processTrainValidation : provides some data preprocessings and creates the training/validation sets\n",
    "* sampler : a utlity class used for sampling stochastically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class processTrainValidation:\n",
    "    def __init__(self, k, image_data, keypoint_data):\n",
    "        self.k = k\n",
    "        \n",
    "        self.image_data = image_data\n",
    "        self.keypoint_data = keypoint_data\n",
    "        self._process()\n",
    "        \n",
    "        self.N = len(image_data)\n",
    "        self.splitter = lambda i : int((i/self.k)*self.N)\n",
    "        \n",
    "    def _process(self):\n",
    "        self.X = self.image_data.values\n",
    "        self.X = np.array([np.array(x) for x in self.X])\n",
    "        \n",
    "        self.Y = self.keypoint_data[self.keypoint_data.columns].values\n",
    "        \n",
    "        del self.image_data\n",
    "        del self.keypoint_data\n",
    "        gc.collect()\n",
    "        \n",
    "    def create_set(self, I):\n",
    "        X_val, X_train = self.X[self.splitter(I):self.splitter(I+1)], \\\n",
    "        np.concatenate([self.X[self.splitter(0):self.splitter(I)],self.X[self.splitter(I+1):]])\n",
    "        y_val, y_train = self.Y[self.splitter(I):self.splitter(I+1)], \\\n",
    "        np.concatenate([self.Y[self.splitter(0):self.splitter(I)],self.Y[self.splitter(I+1):]])\n",
    "        \n",
    "        return X_train, y_train, X_val, y_val\n",
    "    \n",
    "class sampler:\n",
    "    def __init__(self, indices, sample_size):\n",
    "        self.indices = indices\n",
    "        self.sample_size = sample_size\n",
    "        self.dontStop = True\n",
    "        \n",
    "    def sample(self):\n",
    "        self.dontStop = len(self.indices) > self.sample_size\n",
    "        \n",
    "        if not self.dontStop:\n",
    "            return self.indices\n",
    "        sample = np.random.choice(self.indices,self.sample_size,False)\n",
    "        self.indices = list(set(self.indices) - set(sample))\n",
    "        return sample\n",
    "    \n",
    "    def getDontStop(self):\n",
    "        return self.dontStop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define two models:\n",
    "* A model completely built from linear models (called lin_mod), which is our benchmark model.\n",
    "* A model which includes a CNN (call cnn_mod)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class c_unit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(c_unit, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size)\n",
    "        self.conv1_bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x, with_max_pool = True):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv1_bn(x)\n",
    "        x = F.relu(x)\n",
    "        if with_max_pool:\n",
    "            x = F.max_pool2d(x, kernel_size=2)\n",
    "        return x\n",
    "    \n",
    "class r_unit(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(r_unit, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, out_dim)\n",
    "        self.bm = nn.BatchNorm1d(out_dim)\n",
    "        \n",
    "    def forward(self, x, with_batch_norm = False):\n",
    "        x = self.fc1(x)\n",
    "        if with_batch_norm:\n",
    "            x = self.bm(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "    \n",
    "class lin_mod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lin_mod, self).__init__()        \n",
    "        self.r_unit_1 = r_unit(9216, 30)\n",
    "        self.dp1 = nn.Dropout(p=0.4)\n",
    "    \n",
    "    def forward(self, x, verbose=False):\n",
    "        x = x.view(-1, 9216)\n",
    "        \n",
    "        x = self.r_unit_1(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "class cnn_mod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn_mod, self).__init__()\n",
    "        self.c_unit_1 = c_unit(1,12,2)\n",
    "        self.c_unit_2 = c_unit(12,64,2)\n",
    "        self.c_unit_3 = c_unit(64,128,2)\n",
    "        self.c_unit_4 = c_unit(128,256,2)\n",
    "        self.c_unit_5 = c_unit(256,512,2)\n",
    "        \n",
    "        self.r_unit_1 = r_unit(512*2*2, 1024)\n",
    "        self.r_unit_2 = r_unit(1024,256)\n",
    "        self.r_unit_3 = r_unit(256,30)\n",
    "        self.dp1 = nn.Dropout(p=0.4)\n",
    "    \n",
    "    def forward(self, x, verbose=False):\n",
    "        x = self.c_unit_1(x)\n",
    "        x = self.dp1(x)\n",
    "    \n",
    "        x = self.c_unit_2(x)\n",
    "        x = self.dp1(x)\n",
    "        \n",
    "        x = self.c_unit_3(x)\n",
    "        x = self.dp1(x)\n",
    "        \n",
    "        x = self.c_unit_4(x)\n",
    "        x = self.dp1(x)\n",
    "        \n",
    "        x = self.c_unit_5(x)\n",
    "        x = self.dp1(x)\n",
    "\n",
    "        x = x.view(-1, 512*2*2)\n",
    "        \n",
    "        # now use FC layer with relu\n",
    "        x = self.r_unit_1(x, True)\n",
    "        x = self.dp1(x)\n",
    "        \n",
    "        x = self.r_unit_2(x, True)\n",
    "        x = self.dp1(x)\n",
    "        \n",
    "        x = self.r_unit_3(x)\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data_sampler, number_of_epochs, X_train, X_val, y_train, y_val, model, optimiser,\\\n",
    "         criterion,metric, validate_every, l,v,m,_):\n",
    "    N = len(X_train)\n",
    "    i = 0\n",
    "    while data_sampler.getDontStop():\n",
    "        sample = data_sampler.sample()\n",
    "        XX = torch.tensor(X_train[sample]).view(-1,1,96,96).cuda().float()\n",
    "        YY = torch.tensor(y_train[sample]).cuda().float()\n",
    "        \n",
    "        loss = criterion(model(XX),YY)\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "            \n",
    "        optimiser.step()\n",
    "        l.append(loss.item())\n",
    "        Pyloss = loss.item()\n",
    "        del loss\n",
    "        del XX\n",
    "        del YY\n",
    "        gc.collect()\n",
    "            \n",
    "        print('\\r', 'Epoch', _, 'Iteration',i,'of',int(N/data_sampler.sample_size), 'current_loss',Pyloss,end='')\n",
    "        i+=1\n",
    "            \n",
    "    if _%validate_every==0:\n",
    "        XX = torch.tensor(X_val).view(-1,1,96,96).cuda().float()\n",
    "        YY = torch.tensor(y_val).cuda().float()\n",
    "        val_loss = criterion(model(XX),YY)\n",
    "        v.append(val_loss.item())\n",
    "        PyVal_loss = val_loss.item()\n",
    "        mae = metric(model(XX),YY)\n",
    "        PyMae = mae.item()\n",
    "        m.append(PyMae)\n",
    "        del val_loss\n",
    "        del mae\n",
    "        del XX\n",
    "        del YY\n",
    "        print(' ')\n",
    "        print('loss : ', Pyloss)\n",
    "        print('validation loss : ', PyVal_loss)\n",
    "        print('MAE : ', PyMae)\n",
    "        print(' ')\n",
    "\n",
    "    if (len(v) >2 ) and v[-1] - v[-2] < 0:\n",
    "        optimiser.param_groups[0]['lr'] = optimiser.param_groups[0]['lr']/10\n",
    "        print('Optimiser learning rate reduced to '+str(optimiser.param_groups[0]['lr']))\n",
    "        \n",
    "    return l,v,m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now perform a grid search along two axis: \n",
    "* preprocessing : forwadFill, constantMean and sampleDist\n",
    "* Model used : lin_mod and cnn_mod\n",
    "\n",
    "We do this over 5 validation sets, over 15 epochs and average over the validation sets score to gain a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_validate(criterion, metric, process_train_validation,model, number_of_epochs,\\\n",
    "                      sample_size, weight_init):\n",
    "    Loss, Validation, MeanAbsError = [],[],[]\n",
    "    for I in range(0,process_train_validation.k):\n",
    "        print('TRAIN/VAL SET NUMBER : ',I)\n",
    "        X_train, y_train, X_val, y_val = pTV.create_set(I)    \n",
    "        model.load_state_dict(weight_init)\n",
    "        model.cuda()\n",
    "        optimiser = optim.Adam(model.parameters(), lr=0.01,amsgrad=True)\n",
    "\n",
    "        l, v, m = [], [], []\n",
    "        clip = 0.1\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
    "        loss = None\n",
    "\n",
    "        idxs = np.arange(X_train.shape[0])\n",
    "        N = len(idxs)\n",
    "\n",
    "        for _ in range(number_of_epochs):\n",
    "            data_sampler = sampler(idxs, sample_size)\n",
    "            l,v,m = train(data_sampler, number_of_epochs, X_train, X_val, y_train, y_val, model, optimiser,\\\n",
    "             criterion,metric,1,l,v,m,_)\n",
    "            \n",
    "        Loss.append(l)\n",
    "        Validation.append(v)\n",
    "        MeanAbsError.append(m)\n",
    "        \n",
    "    return Loss, Validation, MeanAbsError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "metric = nn.L1Loss()\n",
    "sample_size = 300\n",
    "number_of_epochs = 5\n",
    "\n",
    "\n",
    "results = {'lin_mod' : {'forwardFill' : 0 ,'constantMean' : 0, 'sampleDist' : 0},\\\n",
    "           'cnn_mod' :{'forwardFill' : 0 ,'constantMean' : 0, 'sampleDist' : 0}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= process : forwardFill =========\n",
      "TRAIN/VAL SET NUMBER :  0\n",
      " Epoch 0 Iteration 18 of 18 current_loss 331.9457092285156 \n",
      "loss :  331.9457092285156\n",
      "validation loss :  371.2093200683594\n",
      "MAE :  14.878593444824219\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 221.45811462402344 \n",
      "loss :  221.45811462402344\n",
      "validation loss :  283.79791259765625\n",
      "MAE :  12.323972702026367\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 203.42770385742188 \n",
      "loss :  203.42770385742188\n",
      "validation loss :  230.20321655273438\n",
      "MAE :  11.231263160705566\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 176.22784423828125 \n",
      "loss :  176.22784423828125\n",
      "validation loss :  239.03305053710938\n",
      "MAE :  11.326952934265137\n",
      " \n",
      " Epoch 4 Iteration 18 of 18 current_loss 200.58444213867188 \n",
      "loss :  200.58444213867188\n",
      "validation loss :  239.97042846679688\n",
      "MAE :  11.37493896484375\n",
      " \n",
      "TRAIN/VAL SET NUMBER :  1\n",
      " Epoch 0 Iteration 18 of 18 current_loss 307.4214782714844 \n",
      "loss :  307.4214782714844\n",
      "validation loss :  287.47125244140625\n",
      "MAE :  12.998046875\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 226.81275939941406 \n",
      "loss :  226.81275939941406\n",
      "validation loss :  223.23385620117188\n",
      "MAE :  11.228293418884277\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 177.73765563964844 \n",
      "loss :  177.73765563964844\n",
      "validation loss :  215.60289001464844\n",
      "MAE :  11.044021606445312\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 180.95684814453125 \n",
      "loss :  180.95684814453125\n",
      "validation loss :  211.17921447753906\n",
      "MAE :  10.847076416015625\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 160.0731201171875 \n",
      "loss :  160.0731201171875\n",
      "validation loss :  210.2058868408203\n",
      "MAE :  10.80843448638916\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  2\n",
      " Epoch 0 Iteration 18 of 18 current_loss 307.22857666015625 \n",
      "loss :  307.22857666015625\n",
      "validation loss :  324.6981201171875\n",
      "MAE :  13.418488502502441\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 184.8102264404297 \n",
      "loss :  184.8102264404297\n",
      "validation loss :  225.80836486816406\n",
      "MAE :  11.152645111083984\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 186.0645751953125 \n",
      "loss :  186.0645751953125\n",
      "validation loss :  209.59323120117188\n",
      "MAE :  10.622785568237305\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 165.94174194335938 \n",
      "loss :  165.94174194335938\n",
      "validation loss :  204.69818115234375\n",
      "MAE :  10.499784469604492\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 174.77810668945312 \n",
      "loss :  174.77810668945312\n",
      "validation loss :  204.06317138671875\n",
      "MAE :  10.481036186218262\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  3\n",
      " Epoch 0 Iteration 18 of 18 current_loss 290.14874267578125 \n",
      "loss :  290.14874267578125\n",
      "validation loss :  308.2452392578125\n",
      "MAE :  13.175156593322754\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 207.3557586669922 \n",
      "loss :  207.3557586669922\n",
      "validation loss :  234.06051635742188\n",
      "MAE :  11.300214767456055\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 194.07716369628906 \n",
      "loss :  194.07716369628906\n",
      "validation loss :  207.49398803710938\n",
      "MAE :  10.584992408752441\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 145.6293182373047 \n",
      "loss :  145.6293182373047\n",
      "validation loss :  205.7686309814453\n",
      "MAE :  10.552802085876465\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 170.69400024414062 \n",
      "loss :  170.69400024414062\n",
      "validation loss :  205.1941680908203\n",
      "MAE :  10.537368774414062\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  4\n",
      " Epoch 0 Iteration 18 of 18 current_loss 311.8386535644531 \n",
      "loss :  311.8386535644531\n",
      "validation loss :  337.9176025390625\n",
      "MAE :  13.829157829284668\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 227.5316925048828 \n",
      "loss :  227.5316925048828\n",
      "validation loss :  238.7567901611328\n",
      "MAE :  11.36645221710205\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 172.60348510742188 \n",
      "loss :  172.60348510742188\n",
      "validation loss :  217.31622314453125\n",
      "MAE :  10.734010696411133\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 165.22691345214844 \n",
      "loss :  165.22691345214844\n",
      "validation loss :  214.25894165039062\n",
      "MAE :  10.673665046691895\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 164.90362548828125 \n",
      "loss :  164.90362548828125\n",
      "validation loss :  213.6478729248047\n",
      "MAE :  10.651183128356934\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "========= process : constantMean =========\n",
      "TRAIN/VAL SET NUMBER :  0\n",
      " Epoch 0 Iteration 18 of 18 current_loss 346.86297607421875 \n",
      "loss :  346.86297607421875\n",
      "validation loss :  409.44122314453125\n",
      "MAE :  15.186497688293457\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 220.61746215820312 \n",
      "loss :  220.61746215820312\n",
      "validation loss :  285.5850524902344\n",
      "MAE :  12.309137344360352\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 205.06993103027344 \n",
      "loss :  205.06993103027344\n",
      "validation loss :  230.94236755371094\n",
      "MAE :  11.276083946228027\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 195.5518035888672 \n",
      "loss :  195.5518035888672\n",
      "validation loss :  242.3683624267578\n",
      "MAE :  11.327024459838867\n",
      " \n",
      " Epoch 4 Iteration 18 of 18 current_loss 207.8614959716797 \n",
      "loss :  207.8614959716797\n",
      "validation loss :  234.9745635986328\n",
      "MAE :  11.138794898986816\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      "TRAIN/VAL SET NUMBER :  1\n",
      " Epoch 0 Iteration 18 of 18 current_loss 311.69244384765625 \n",
      "loss :  311.69244384765625\n",
      "validation loss :  295.76934814453125\n",
      "MAE :  13.190409660339355\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 203.94598388671875 \n",
      "loss :  203.94598388671875\n",
      "validation loss :  229.1157684326172\n",
      "MAE :  11.507442474365234\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 193.54637145996094 \n",
      "loss :  193.54637145996094\n",
      "validation loss :  220.29844665527344\n",
      "MAE :  11.278444290161133\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 191.42628479003906 \n",
      "loss :  191.42628479003906\n",
      "validation loss :  212.41111755371094\n",
      "MAE :  11.01646900177002\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 187.5635528564453 \n",
      "loss :  187.5635528564453\n",
      "validation loss :  211.79898071289062\n",
      "MAE :  10.994246482849121\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  2\n",
      " Epoch 0 Iteration 18 of 18 current_loss 329.8767395019531 \n",
      "loss :  329.8767395019531\n",
      "validation loss :  307.943359375\n",
      "MAE :  13.109183311462402\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 184.94351196289062 \n",
      "loss :  184.94351196289062\n",
      "validation loss :  228.23687744140625\n",
      "MAE :  11.292237281799316\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 193.9348602294922 \n",
      "loss :  193.9348602294922\n",
      "validation loss :  211.63290405273438\n",
      "MAE :  10.78462028503418\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 149.5635223388672 \n",
      "loss :  149.5635223388672\n",
      "validation loss :  198.48574829101562\n",
      "MAE :  10.335201263427734\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 151.0929718017578 \n",
      "loss :  151.0929718017578\n",
      "validation loss :  198.42848205566406\n",
      "MAE :  10.332826614379883\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  3\n",
      " Epoch 0 Iteration 18 of 18 current_loss 304.5893249511719 \n",
      "loss :  304.5893249511719\n",
      "validation loss :  310.24188232421875\n",
      "MAE :  13.248015403747559\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 236.6000213623047 \n",
      "loss :  236.6000213623047\n",
      "validation loss :  236.68870544433594\n",
      "MAE :  11.625313758850098\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 185.78231811523438 \n",
      "loss :  185.78231811523438\n",
      "validation loss :  206.65219116210938\n",
      "MAE :  10.691946029663086\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 173.04713439941406 \n",
      "loss :  173.04713439941406\n",
      "validation loss :  202.76971435546875\n",
      "MAE :  10.524809837341309\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 128.71414184570312 \n",
      "loss :  128.71414184570312\n",
      "validation loss :  202.11300659179688\n",
      "MAE :  10.504453659057617\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  4\n",
      " Epoch 0 Iteration 18 of 18 current_loss 293.48883056640625 \n",
      "loss :  293.48883056640625\n",
      "validation loss :  307.969970703125\n",
      "MAE :  13.213056564331055\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 213.5603485107422 \n",
      "loss :  213.5603485107422\n",
      "validation loss :  238.27467346191406\n",
      "MAE :  11.542407035827637\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 149.76158142089844 \n",
      "loss :  149.76158142089844\n",
      "validation loss :  220.47747802734375\n",
      "MAE :  10.989849090576172\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 185.89901733398438 \n",
      "loss :  185.89901733398438\n",
      "validation loss :  207.91650390625\n",
      "MAE :  10.531085014343262\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 161.7760772705078 \n",
      "loss :  161.7760772705078\n",
      "validation loss :  207.3402557373047\n",
      "MAE :  10.504855155944824\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "========= process : sampleDist =========\n",
      "TRAIN/VAL SET NUMBER :  0\n",
      " Epoch 0 Iteration 18 of 18 current_loss 292.6380615234375 \n",
      "loss :  292.6380615234375\n",
      "validation loss :  405.1730651855469\n",
      "MAE :  15.480180740356445\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 211.6427764892578 \n",
      "loss :  211.6427764892578\n",
      "validation loss :  286.74530029296875\n",
      "MAE :  12.325894355773926\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 188.4943084716797 \n",
      "loss :  188.4943084716797\n",
      "validation loss :  253.83212280273438\n",
      "MAE :  11.669048309326172\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 163.20516967773438 \n",
      "loss :  163.20516967773438\n",
      "validation loss :  236.71693420410156\n",
      "MAE :  11.218118667602539\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 205.2962188720703 \n",
      "loss :  205.2962188720703\n",
      "validation loss :  235.90716552734375\n",
      "MAE :  11.204410552978516\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  1\n",
      " Epoch 0 Iteration 18 of 18 current_loss 303.214599609375 \n",
      "loss :  303.214599609375\n",
      "validation loss :  298.01654052734375\n",
      "MAE :  13.261886596679688\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 218.51760864257812 \n",
      "loss :  218.51760864257812\n",
      "validation loss :  234.29995727539062\n",
      "MAE :  11.713797569274902\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 198.30250549316406 \n",
      "loss :  198.30250549316406\n",
      "validation loss :  214.05104064941406\n",
      "MAE :  11.003349304199219\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 151.50979614257812 \n",
      "loss :  151.50979614257812\n",
      "validation loss :  209.84288024902344\n",
      "MAE :  10.835474014282227\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 155.35464477539062 \n",
      "loss :  155.35464477539062\n",
      "validation loss :  209.1349334716797\n",
      "MAE :  10.812078475952148\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  2\n",
      " Epoch 0 Iteration 18 of 18 current_loss 301.7822265625 \n",
      "loss :  301.7822265625\n",
      "validation loss :  344.4935607910156\n",
      "MAE :  13.972209930419922\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 229.14926147460938 \n",
      "loss :  229.14926147460938\n",
      "validation loss :  231.56101989746094\n",
      "MAE :  11.47012996673584\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 189.68275451660156 \n",
      "loss :  189.68275451660156\n",
      "validation loss :  218.03192138671875\n",
      "MAE :  11.051753044128418\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 166.04550170898438 \n",
      "loss :  166.04550170898438\n",
      "validation loss :  212.68429565429688\n",
      "MAE :  10.956669807434082\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 163.80892944335938 \n",
      "loss :  163.80892944335938\n",
      "validation loss :  212.76351928710938\n",
      "MAE :  10.956696510314941\n",
      " \n",
      "TRAIN/VAL SET NUMBER :  3\n",
      " Epoch 0 Iteration 18 of 18 current_loss 299.54656982421875 \n",
      "loss :  299.54656982421875\n",
      "validation loss :  328.5380554199219\n",
      "MAE :  13.858471870422363\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 228.84347534179688 \n",
      "loss :  228.84347534179688\n",
      "validation loss :  248.15380859375\n",
      "MAE :  11.990983963012695\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 179.05010986328125 \n",
      "loss :  179.05010986328125\n",
      "validation loss :  218.16510009765625\n",
      "MAE :  11.065540313720703\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 176.11488342285156 \n",
      "loss :  176.11488342285156\n",
      "validation loss :  213.00723266601562\n",
      "MAE :  10.883565902709961\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 183.22093200683594 \n",
      "loss :  183.22093200683594\n",
      "validation loss :  212.0373077392578\n",
      "MAE :  10.844823837280273\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  4\n",
      " Epoch 0 Iteration 18 of 18 current_loss 282.5299377441406 \n",
      "loss :  282.5299377441406\n",
      "validation loss :  335.7270812988281\n",
      "MAE :  13.970307350158691\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 213.46714782714844 \n",
      "loss :  213.46714782714844\n",
      "validation loss :  247.0858154296875\n",
      "MAE :  11.81710433959961\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 188.4199676513672 \n",
      "loss :  188.4199676513672\n",
      "validation loss :  229.15040588378906\n",
      "MAE :  11.364320755004883\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 174.5482635498047 \n",
      "loss :  174.5482635498047\n",
      "validation loss :  224.11473083496094\n",
      "MAE :  11.165916442871094\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 209.77130126953125 \n",
      "loss :  209.77130126953125\n",
      "validation loss :  223.7491912841797\n",
      "MAE :  11.16130256652832\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n"
     ]
    }
   ],
   "source": [
    "#linear model\n",
    "\n",
    "for key in data_processing.keys():\n",
    "    print('========= process : '+key+' =========')\n",
    "    pTV = processTrainValidation(5,df_images,data_processing[key])\n",
    "    model = lin_mod().train()\n",
    "    weight_inits = model.state_dict()\n",
    "\n",
    "    Loss, Validation, Mae = train_and_validate(criterion, metric, pTV, model, number_of_epochs, sample_size,\\\n",
    "                                               weight_inits)\n",
    "    results['lin_mod'][key] = Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= process : forwardFill =========\n",
      "TRAIN/VAL SET NUMBER :  0\n",
      " Epoch 0 Iteration 18 of 18 current_loss 763.10546875 \n",
      "loss :  763.10546875\n",
      "validation loss :  648.9420776367188\n",
      "MAE :  19.23423194885254\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 77.6113052368164 \n",
      "loss :  77.6113052368164\n",
      "validation loss :  96.15045928955078\n",
      "MAE :  7.9897356033325195\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 34.214576721191406 \n",
      "loss :  34.214576721191406\n",
      "validation loss :  46.30091857910156\n",
      "MAE :  5.101644992828369\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 33.91164016723633 \n",
      "loss :  33.91164016723633\n",
      "validation loss :  48.424522399902344\n",
      "MAE :  5.076449871063232\n",
      " \n",
      " Epoch 4 Iteration 18 of 18 current_loss 30.262596130371094 \n",
      "loss :  30.262596130371094\n",
      "validation loss :  44.56303405761719\n",
      "MAE :  4.750637531280518\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      "TRAIN/VAL SET NUMBER :  1\n",
      " Epoch 0 Iteration 18 of 18 current_loss 786.675048828125 \n",
      "loss :  786.675048828125\n",
      "validation loss :  704.1964721679688\n",
      "MAE :  20.37360191345215\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 76.42891693115234 \n",
      "loss :  76.42891693115234\n",
      "validation loss :  80.97563934326172\n",
      "MAE :  7.280383586883545\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 38.372711181640625 \n",
      "loss :  38.372711181640625\n",
      "validation loss :  47.639678955078125\n",
      "MAE :  5.261458873748779\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 31.448379516601562 \n",
      "loss :  31.448379516601562\n",
      "validation loss :  40.386871337890625\n",
      "MAE :  4.854963779449463\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 31.296152114868164 \n",
      "loss :  31.296152114868164\n",
      "validation loss :  39.94237518310547\n",
      "MAE :  4.671908378601074\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  2\n",
      " Epoch 0 Iteration 18 of 18 current_loss 753.6278686523438 \n",
      "loss :  753.6278686523438\n",
      "validation loss :  700.1754150390625\n",
      "MAE :  20.50008201599121\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 76.27790069580078 \n",
      "loss :  76.27790069580078\n",
      "validation loss :  62.42322540283203\n",
      "MAE :  6.448246002197266\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 37.432987213134766 \n",
      "loss :  37.432987213134766\n",
      "validation loss :  35.53823471069336\n",
      "MAE :  4.752561569213867\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 30.046663284301758 \n",
      "loss :  30.046663284301758\n",
      "validation loss :  29.092145919799805\n",
      "MAE :  4.195779323577881\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 40.54402160644531 \n",
      "loss :  40.54402160644531\n",
      "validation loss :  29.597434997558594\n",
      "MAE :  4.1681318283081055\n",
      " \n",
      "TRAIN/VAL SET NUMBER :  3\n",
      " Epoch 0 Iteration 18 of 18 current_loss 784.9947509765625 \n",
      "loss :  784.9947509765625\n",
      "validation loss :  714.3762817382812\n",
      "MAE :  20.73160171508789\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 80.32781219482422 \n",
      "loss :  80.32781219482422\n",
      "validation loss :  65.99598693847656\n",
      "MAE :  6.60930871963501\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 43.607906341552734 \n",
      "loss :  43.607906341552734\n",
      "validation loss :  34.94260787963867\n",
      "MAE :  4.705831527709961\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 38.76234436035156 \n",
      "loss :  38.76234436035156\n",
      "validation loss :  29.5870361328125\n",
      "MAE :  4.286059856414795\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 33.76858139038086 \n",
      "loss :  33.76858139038086\n",
      "validation loss :  28.372596740722656\n",
      "MAE :  4.170810222625732\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  4\n",
      " Epoch 0 Iteration 18 of 18 current_loss 783.1663818359375 \n",
      "loss :  783.1663818359375\n",
      "validation loss :  702.5198364257812\n",
      "MAE :  20.459510803222656\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 80.71794128417969 \n",
      "loss :  80.71794128417969\n",
      "validation loss :  64.61669158935547\n",
      "MAE :  6.471490859985352\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 41.482357025146484 \n",
      "loss :  41.482357025146484\n",
      "validation loss :  37.583221435546875\n",
      "MAE :  4.77282190322876\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 33.00436782836914 \n",
      "loss :  33.00436782836914\n",
      "validation loss :  29.184036254882812\n",
      "MAE :  4.195115089416504\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 32.367069244384766 \n",
      "loss :  32.367069244384766\n",
      "validation loss :  28.533578872680664\n",
      "MAE :  4.068789958953857\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "========= process : constantMean =========\n",
      "TRAIN/VAL SET NUMBER :  0\n",
      " Epoch 0 Iteration 18 of 18 current_loss 741.5997924804688 \n",
      "loss :  741.5997924804688\n",
      "validation loss :  672.52978515625\n",
      "MAE :  19.706043243408203\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 76.25774383544922 \n",
      "loss :  76.25774383544922\n",
      "validation loss :  81.3883056640625\n",
      "MAE :  7.275428771972656\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 34.86418533325195 \n",
      "loss :  34.86418533325195\n",
      "validation loss :  43.591304779052734\n",
      "MAE :  5.1465630531311035\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 28.083782196044922 \n",
      "loss :  28.083782196044922\n",
      "validation loss :  43.29460906982422\n",
      "MAE :  4.934823989868164\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 28.04720115661621 \n",
      "loss :  28.04720115661621\n",
      "validation loss :  42.175811767578125\n",
      "MAE :  4.847426891326904\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  1\n",
      " Epoch 0 Iteration 18 of 18 current_loss 739.0223388671875 \n",
      "loss :  739.0223388671875\n",
      "validation loss :  679.2487182617188\n",
      "MAE :  19.936378479003906\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 79.77474975585938 \n",
      "loss :  79.77474975585938\n",
      "validation loss :  73.20159912109375\n",
      "MAE :  6.944049835205078\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 34.905094146728516 \n",
      "loss :  34.905094146728516\n",
      "validation loss :  42.08650588989258\n",
      "MAE :  5.055429458618164\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 26.078317642211914 \n",
      "loss :  26.078317642211914\n",
      "validation loss :  36.59638977050781\n",
      "MAE :  4.642383575439453\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 27.72997283935547 \n",
      "loss :  27.72997283935547\n",
      "validation loss :  36.62257766723633\n",
      "MAE :  4.5421223640441895\n",
      " \n",
      "TRAIN/VAL SET NUMBER :  2\n",
      " Epoch 0 Iteration 18 of 18 current_loss 751.7615966796875 \n",
      "loss :  751.7615966796875\n",
      "validation loss :  677.3594970703125\n",
      "MAE :  19.849639892578125\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 80.30953979492188 \n",
      "loss :  80.30953979492188\n",
      "validation loss :  64.74320220947266\n",
      "MAE :  6.469119548797607\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 38.206520080566406 \n",
      "loss :  38.206520080566406\n",
      "validation loss :  31.155845642089844\n",
      "MAE :  4.4704365730285645\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 30.52865219116211 \n",
      "loss :  30.52865219116211\n",
      "validation loss :  28.95391273498535\n",
      "MAE :  4.086232662200928\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 33.78944778442383 \n",
      "loss :  33.78944778442383\n",
      "validation loss :  27.78055191040039\n",
      "MAE :  4.075920104980469\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  3\n",
      " Epoch 0 Iteration 18 of 18 current_loss 736.0248413085938 \n",
      "loss :  736.0248413085938\n",
      "validation loss :  668.039794921875\n",
      "MAE :  19.755701065063477\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 73.59100341796875 \n",
      "loss :  73.59100341796875\n",
      "validation loss :  60.483699798583984\n",
      "MAE :  6.4106059074401855\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 33.152339935302734 \n",
      "loss :  33.152339935302734\n",
      "validation loss :  33.67633056640625\n",
      "MAE :  4.564177989959717\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 28.13985824584961 \n",
      "loss :  28.13985824584961\n",
      "validation loss :  30.79139518737793\n",
      "MAE :  4.103410720825195\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 31.006494522094727 \n",
      "loss :  31.006494522094727\n",
      "validation loss :  28.333301544189453\n",
      "MAE :  4.071253776550293\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  4\n",
      " Epoch 0 Iteration 18 of 18 current_loss 760.7507934570312 \n",
      "loss :  760.7507934570312\n",
      "validation loss :  690.1513671875\n",
      "MAE :  20.183948516845703\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 80.4096908569336 \n",
      "loss :  80.4096908569336\n",
      "validation loss :  65.225830078125\n",
      "MAE :  6.677492618560791\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 35.661502838134766 \n",
      "loss :  35.661502838134766\n",
      "validation loss :  33.68083190917969\n",
      "MAE :  4.585317134857178\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 29.783241271972656 \n",
      "loss :  29.783241271972656\n",
      "validation loss :  27.391504287719727\n",
      "MAE :  4.044399261474609\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 29.472864151000977 \n",
      "loss :  29.472864151000977\n",
      "validation loss :  26.902027130126953\n",
      "MAE :  3.9119725227355957\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "========= process : sampleDist =========\n",
      "TRAIN/VAL SET NUMBER :  0\n",
      " Epoch 0 Iteration 18 of 18 current_loss 743.9209594726562 \n",
      "loss :  743.9209594726562\n",
      "validation loss :  669.1996459960938\n",
      "MAE :  19.770788192749023\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 79.46810913085938 \n",
      "loss :  79.46810913085938\n",
      "validation loss :  80.78340148925781\n",
      "MAE :  7.5058722496032715\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 49.54362106323242 \n",
      "loss :  49.54362106323242\n",
      "validation loss :  50.39044952392578\n",
      "MAE :  5.304300785064697\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 33.07830047607422 \n",
      "loss :  33.07830047607422\n",
      "validation loss :  50.47270965576172\n",
      "MAE :  5.322197914123535\n",
      " \n",
      " Epoch 4 Iteration 18 of 18 current_loss 38.42121505737305 \n",
      "loss :  38.42121505737305\n",
      "validation loss :  43.732303619384766\n",
      "MAE :  4.92293643951416\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      "TRAIN/VAL SET NUMBER :  1\n",
      " Epoch 0 Iteration 18 of 18 current_loss 731.29345703125 \n",
      "loss :  731.29345703125\n",
      "validation loss :  669.4902954101562\n",
      "MAE :  19.715015411376953\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 80.03754425048828 \n",
      "loss :  80.03754425048828\n",
      "validation loss :  79.96214294433594\n",
      "MAE :  7.062595367431641\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 37.51255416870117 \n",
      "loss :  37.51255416870117\n",
      "validation loss :  45.228050231933594\n",
      "MAE :  5.124133586883545\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 29.895797729492188 \n",
      "loss :  29.895797729492188\n",
      "validation loss :  39.82778549194336\n",
      "MAE :  4.808548927307129\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 33.3741569519043 \n",
      "loss :  33.3741569519043\n",
      "validation loss :  38.28859329223633\n",
      "MAE :  4.802947521209717\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  2\n",
      " Epoch 0 Iteration 18 of 18 current_loss 779.350830078125 \n",
      "loss :  779.350830078125\n",
      "validation loss :  688.5576171875\n",
      "MAE :  20.3493595123291\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 83.10929107666016 \n",
      "loss :  83.10929107666016\n",
      "validation loss :  73.69600677490234\n",
      "MAE :  7.044457912445068\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 38.76826095581055 \n",
      "loss :  38.76826095581055\n",
      "validation loss :  43.281795501708984\n",
      "MAE :  5.189229488372803\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 33.93929672241211 \n",
      "loss :  33.93929672241211\n",
      "validation loss :  37.92280578613281\n",
      "MAE :  4.783779144287109\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 38.12686538696289 \n",
      "loss :  38.12686538696289\n",
      "validation loss :  37.39053726196289\n",
      "MAE :  4.649501800537109\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n",
      "TRAIN/VAL SET NUMBER :  3\n",
      " Epoch 0 Iteration 18 of 18 current_loss 763.864013671875 \n",
      "loss :  763.864013671875\n",
      "validation loss :  670.958984375\n",
      "MAE :  19.92032241821289\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 85.8375015258789 \n",
      "loss :  85.8375015258789\n",
      "validation loss :  70.78834533691406\n",
      "MAE :  6.807217121124268\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 38.921207427978516 \n",
      "loss :  38.921207427978516\n",
      "validation loss :  40.97317123413086\n",
      "MAE :  5.087099552154541\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 34.46118927001953 \n",
      "loss :  34.46118927001953\n",
      "validation loss :  36.24489212036133\n",
      "MAE :  4.6799821853637695\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 37.87879180908203 \n",
      "loss :  37.87879180908203\n",
      "validation loss :  36.56145477294922\n",
      "MAE :  4.724085330963135\n",
      " \n",
      "TRAIN/VAL SET NUMBER :  4\n",
      " Epoch 0 Iteration 18 of 18 current_loss 807.1189575195312 \n",
      "loss :  807.1189575195312\n",
      "validation loss :  717.1599731445312\n",
      "MAE :  20.86956787109375\n",
      " \n",
      " Epoch 1 Iteration 18 of 18 current_loss 88.11485290527344 \n",
      "loss :  88.11485290527344\n",
      "validation loss :  76.66254425048828\n",
      "MAE :  7.205941200256348\n",
      " \n",
      " Epoch 2 Iteration 18 of 18 current_loss 43.138057708740234 \n",
      "loss :  43.138057708740234\n",
      "validation loss :  41.14793014526367\n",
      "MAE :  5.149716377258301\n",
      " \n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 18 of 18 current_loss 36.9005241394043 \n",
      "loss :  36.9005241394043\n",
      "validation loss :  37.115482330322266\n",
      "MAE :  4.771690845489502\n",
      " \n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 18 of 18 current_loss 35.98335647583008 \n",
      "loss :  35.98335647583008\n",
      "validation loss :  36.91164016723633\n",
      "MAE :  4.675521373748779\n",
      " \n",
      "Optimiser learning rate reduced to 1e-05\n"
     ]
    }
   ],
   "source": [
    "#cnn model\n",
    "\n",
    "for key in data_processing.keys():\n",
    "    print('========= process : '+key+' =========')\n",
    "    pTV = processTrainValidation(5,df_images,data_processing[key])\n",
    "    model = cnn_mod().train()\n",
    "    weight_inits = model.state_dict()\n",
    "\n",
    "    Loss, Validation, Mae = train_and_validate(criterion, metric, pTV, model, number_of_epochs, sample_size,\\\n",
    "                                               weight_inits)\n",
    "    results['cnn_mod'][key] = Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_obj(results,'validation_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Pick a model and train on full data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing processing/model is constantMean with cnn_mod, so we know train on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data_sampler, number_of_epochs, X_train, y_train, model, optimiser, criterion,metric, l, m, _):\n",
    "    N = len(X_train)\n",
    "    i = 0\n",
    "    while data_sampler.getDontStop():\n",
    "        sample = data_sampler.sample()\n",
    "        XX = torch.tensor(X_train[sample]).view(-1,1,96,96).cuda().float()\n",
    "        YY = torch.tensor(y_train[sample]).cuda().float()\n",
    "        \n",
    "        predict = model(XX)\n",
    "        \n",
    "        loss = criterion(predict,YY)\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "            \n",
    "        optimiser.step()\n",
    "        l.append(loss.item())\n",
    "        Pyloss = loss.item()\n",
    "        mae = metric(predict, YY)\n",
    "        PyMae = mae.item()\n",
    "        m.append(PyMae)\n",
    "        del loss\n",
    "        del XX\n",
    "        del YY\n",
    "        del mae\n",
    "        gc.collect()\n",
    "            \n",
    "        print('\\r', 'Epoch', _, 'Iteration',i,'of',int(N/data_sampler.sample_size), 'current_loss',Pyloss,end='')\n",
    "        i+=1\n",
    "    return l,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0 Iteration 23 of 23 current_loss 413.61749267578125\n",
      "Epoch 0\n",
      "current loss :  413.61749267578125\n",
      "current mae :  14.792744636535645\n",
      " Epoch 1 Iteration 23 of 23 current_loss 38.278804779052734\n",
      "Epoch 1\n",
      "current loss :  38.278804779052734\n",
      "current mae :  4.774612903594971\n",
      " Epoch 2 Iteration 23 of 23 current_loss 30.02244758605957\n",
      "Epoch 2\n",
      "current loss :  30.02244758605957\n",
      "current mae :  4.147800922393799\n",
      "Optimiser learning rate reduced to 0.001\n",
      " Epoch 3 Iteration 23 of 23 current_loss 20.120912551879883\n",
      "Epoch 3\n",
      "current loss :  20.120912551879883\n",
      "current mae :  3.320603370666504\n",
      "Optimiser learning rate reduced to 0.0001\n",
      " Epoch 4 Iteration 23 of 23 current_loss 22.506284713745117\n",
      "Epoch 4\n",
      "current loss :  22.506284713745117\n",
      "current mae :  3.4401516914367676\n",
      " Epoch 5 Iteration 23 of 23 current_loss 21.847375869750977\n",
      "Epoch 5\n",
      "current loss :  21.847375869750977\n",
      "current mae :  3.4269003868103027\n",
      "Optimiser learning rate reduced to 1e-05\n",
      " Epoch 6 Iteration 23 of 23 current_loss 23.75849151611328\n",
      "Epoch 6\n",
      "current loss :  23.75849151611328\n",
      "current mae :  3.407137393951416\n",
      "Optimiser learning rate reduced to 1.0000000000000002e-06\n",
      " Epoch 7 Iteration 23 of 23 current_loss 20.59647560119629\n",
      "Epoch 7\n",
      "current loss :  20.59647560119629\n",
      "current mae :  3.3451385498046875\n",
      "Optimiser learning rate reduced to 1.0000000000000002e-07\n",
      " Epoch 8 Iteration 23 of 23 current_loss 27.14337158203125\n",
      "Epoch 8\n",
      "current loss :  27.14337158203125\n",
      "current mae :  3.7102291584014893\n",
      " Epoch 9 Iteration 23 of 23 current_loss 23.33572769165039\n",
      "Epoch 9\n",
      "current loss :  23.33572769165039\n",
      "current mae :  3.6293177604675293\n",
      "Optimiser learning rate reduced to 1.0000000000000002e-08\n",
      " Epoch 10 Iteration 23 of 23 current_loss 21.201799392700195\n",
      "Epoch 10\n",
      "current loss :  21.201799392700195\n",
      "current mae :  3.353456735610962\n",
      "Optimiser learning rate reduced to 1.0000000000000003e-09\n",
      " Epoch 11 Iteration 23 of 23 current_loss 25.978605270385742\n",
      "Epoch 11\n",
      "current loss :  25.978605270385742\n",
      "current mae :  3.7232723236083984\n",
      " Epoch 12 Iteration 23 of 23 current_loss 24.707040786743164\n",
      "Epoch 12\n",
      "current loss :  24.707040786743164\n",
      "current mae :  3.7767302989959717\n",
      " Epoch 13 Iteration 23 of 23 current_loss 29.722497940063477\n",
      "Epoch 13\n",
      "current loss :  29.722497940063477\n",
      "current mae :  3.9174556732177734\n",
      " Epoch 14 Iteration 23 of 23 current_loss 25.7269287109375\n",
      "Epoch 14\n",
      "current loss :  25.7269287109375\n",
      "current mae :  3.631845712661743\n",
      "Optimiser learning rate reduced to 1.0000000000000003e-10\n",
      " Epoch 15 Iteration 23 of 23 current_loss 23.6180362701416\n",
      "Epoch 15\n",
      "current loss :  23.6180362701416\n",
      "current mae :  3.6625709533691406\n",
      " Epoch 16 Iteration 23 of 23 current_loss 23.831321716308594\n",
      "Epoch 16\n",
      "current loss :  23.831321716308594\n",
      "current mae :  3.616741895675659\n",
      "Optimiser learning rate reduced to 1.0000000000000003e-11\n",
      " Epoch 17 Iteration 23 of 23 current_loss 24.46698570251465\n",
      "Epoch 17\n",
      "current loss :  24.46698570251465\n",
      "current mae :  3.6089847087860107\n",
      "Optimiser learning rate reduced to 1.0000000000000002e-12\n",
      " Epoch 18 Iteration 23 of 23 current_loss 25.833106994628906\n",
      "Epoch 18\n",
      "current loss :  25.833106994628906\n",
      "current mae :  3.8104255199432373\n",
      " Epoch 19 Iteration 23 of 23 current_loss 30.782119750976562\n",
      "Epoch 19\n",
      "current loss :  30.782119750976562\n",
      "current mae :  4.116121768951416\n",
      " Epoch 20 Iteration 23 of 23 current_loss 23.56726837158203\n",
      "Epoch 20\n",
      "current loss :  23.56726837158203\n",
      "current mae :  3.536072254180908\n",
      "Optimiser learning rate reduced to 1.0000000000000002e-13\n",
      " Epoch 21 Iteration 23 of 23 current_loss 21.99661636352539\n",
      "Epoch 21\n",
      "current loss :  21.99661636352539\n",
      "current mae :  3.4636528491973877\n",
      "Optimiser learning rate reduced to 1.0000000000000002e-14\n",
      " Epoch 22 Iteration 23 of 23 current_loss 25.777742385864258\n",
      "Epoch 22\n",
      "current loss :  25.777742385864258\n",
      "current mae :  3.883850574493408\n",
      " Epoch 23 Iteration 23 of 23 current_loss 24.240524291992188\n",
      "Epoch 23\n",
      "current loss :  24.240524291992188\n",
      "current mae :  3.60898756980896\n",
      "Optimiser learning rate reduced to 1e-15\n",
      " Epoch 24 Iteration 23 of 23 current_loss 27.8619327545166\n",
      "Epoch 24\n",
      "current loss :  27.8619327545166\n",
      "current mae :  3.943704128265381\n",
      " Epoch 25 Iteration 23 of 23 current_loss 25.816707611083984\n",
      "Epoch 25\n",
      "current loss :  25.816707611083984\n",
      "current mae :  3.8058769702911377\n",
      "Optimiser learning rate reduced to 1.0000000000000001e-16\n",
      " Epoch 26 Iteration 23 of 23 current_loss 28.183141708374023\n",
      "Epoch 26\n",
      "current loss :  28.183141708374023\n",
      "current mae :  3.8939707279205322\n",
      " Epoch 27 Iteration 23 of 23 current_loss 20.978849411010742\n",
      "Epoch 27\n",
      "current loss :  20.978849411010742\n",
      "current mae :  3.3998899459838867\n",
      "Optimiser learning rate reduced to 1e-17\n",
      " Epoch 28 Iteration 23 of 23 current_loss 25.07501983642578\n",
      "Epoch 28\n",
      "current loss :  25.07501983642578\n",
      "current mae :  3.6005704402923584\n",
      " Epoch 29 Iteration 23 of 23 current_loss 26.51868438720703\n",
      "Epoch 29\n",
      "current loss :  26.51868438720703\n",
      "current mae :  3.8364133834838867\n",
      " Epoch 30 Iteration 23 of 23 current_loss 22.58550262451172\n",
      "Epoch 30\n",
      "current loss :  22.58550262451172\n",
      "current mae :  3.4990789890289307\n",
      "Optimiser learning rate reduced to 1e-18\n",
      " Epoch 31 Iteration 23 of 23 current_loss 24.95261573791504\n",
      "Epoch 31\n",
      "current loss :  24.95261573791504\n",
      "current mae :  3.6955013275146484\n",
      " Epoch 32 Iteration 23 of 23 current_loss 24.483808517456055\n",
      "Epoch 32\n",
      "current loss :  24.483808517456055\n",
      "current mae :  3.6379916667938232\n",
      "Optimiser learning rate reduced to 1.0000000000000001e-19\n",
      " Epoch 33 Iteration 23 of 23 current_loss 21.481430053710938\n",
      "Epoch 33\n",
      "current loss :  21.481430053710938\n",
      "current mae :  3.435758113861084\n",
      "Optimiser learning rate reduced to 1.0000000000000001e-20\n",
      " Epoch 34 Iteration 23 of 23 current_loss 30.349769592285156\n",
      "Epoch 34\n",
      "current loss :  30.349769592285156\n",
      "current mae :  4.127889633178711\n",
      " Epoch 35 Iteration 23 of 23 current_loss 23.689172744750977\n",
      "Epoch 35\n",
      "current loss :  23.689172744750977\n",
      "current mae :  3.4567339420318604\n",
      "Optimiser learning rate reduced to 1.0000000000000001e-21\n",
      " Epoch 36 Iteration 23 of 23 current_loss 25.038190841674805\n",
      "Epoch 36\n",
      "current loss :  25.038190841674805\n",
      "current mae :  3.7013120651245117\n",
      " Epoch 37 Iteration 23 of 23 current_loss 20.82500648498535\n",
      "Epoch 37\n",
      "current loss :  20.82500648498535\n",
      "current mae :  3.3901658058166504\n",
      "Optimiser learning rate reduced to 1e-22\n",
      " Epoch 38 Iteration 23 of 23 current_loss 26.368764877319336\n",
      "Epoch 38\n",
      "current loss :  26.368764877319336\n",
      "current mae :  3.8254849910736084\n",
      " Epoch 39 Iteration 23 of 23 current_loss 24.234514236450195\n",
      "Epoch 39\n",
      "current loss :  24.234514236450195\n",
      "current mae :  3.581247091293335\n",
      "Optimiser learning rate reduced to 1.0000000000000001e-23\n",
      " Epoch 40 Iteration 23 of 23 current_loss 26.573585510253906\n",
      "Epoch 40\n",
      "current loss :  26.573585510253906\n",
      "current mae :  3.6589443683624268\n",
      " Epoch 41 Iteration 23 of 23 current_loss 24.58131980895996\n",
      "Epoch 41\n",
      "current loss :  24.58131980895996\n",
      "current mae :  3.594193458557129\n",
      "Optimiser learning rate reduced to 1.0000000000000001e-24\n",
      " Epoch 42 Iteration 23 of 23 current_loss 23.28362274169922\n",
      "Epoch 42\n",
      "current loss :  23.28362274169922\n",
      "current mae :  3.575227975845337\n",
      "Optimiser learning rate reduced to 1.0000000000000002e-25\n",
      " Epoch 43 Iteration 23 of 23 current_loss 25.154312133789062\n",
      "Epoch 43\n",
      "current loss :  25.154312133789062\n",
      "current mae :  3.6906375885009766\n",
      " Epoch 44 Iteration 23 of 23 current_loss 28.63541603088379\n",
      "Epoch 44\n",
      "current loss :  28.63541603088379\n",
      "current mae :  3.917060375213623\n",
      " Epoch 45 Iteration 23 of 23 current_loss 22.00837516784668\n",
      "Epoch 45\n",
      "current loss :  22.00837516784668\n",
      "current mae :  3.5058655738830566\n",
      "Optimiser learning rate reduced to 1.0000000000000002e-26\n",
      " Epoch 46 Iteration 23 of 23 current_loss 21.564136505126953\n",
      "Epoch 46\n",
      "current loss :  21.564136505126953\n",
      "current mae :  3.4259753227233887\n",
      "Optimiser learning rate reduced to 1.0000000000000002e-27\n",
      " Epoch 47 Iteration 23 of 23 current_loss 29.885242462158203\n",
      "Epoch 47\n",
      "current loss :  29.885242462158203\n",
      "current mae :  3.7578492164611816\n",
      " Epoch 48 Iteration 23 of 23 current_loss 19.568408966064453\n",
      "Epoch 48\n",
      "current loss :  19.568408966064453\n",
      "current mae :  3.252054452896118\n",
      "Optimiser learning rate reduced to 1.0000000000000002e-28\n",
      " Epoch 49 Iteration 23 of 23 current_loss 24.85744285583496\n",
      "Epoch 49\n",
      "current loss :  24.85744285583496\n",
      "current mae :  3.658900499343872\n"
     ]
    }
   ],
   "source": [
    "y_train = data_processing['constantMean'].values\n",
    "X_train = df_images.values\n",
    "X_train = np.array([np.array(x) for x in X_train])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "metric = nn.L1Loss()\n",
    "\n",
    "model = cnn_mod().train()\n",
    "\n",
    "number_of_epochs = 50\n",
    "sample_size = 300\n",
    "model.cuda()\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.01,amsgrad=True)\n",
    "\n",
    "l, m = [], [],\n",
    "clip = 0.1\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
    "loss = None\n",
    "\n",
    "idxs = np.arange(X_train.shape[0])\n",
    "N = len(idxs)\n",
    "\n",
    "epoch_level_mae = []\n",
    "\n",
    "for _ in range(number_of_epochs):\n",
    "    data_sampler = sampler(idxs, sample_size)\n",
    "    l,m = train(data_sampler, number_of_epochs, X_train, y_train, model, optimiser,criterion, metric, l,m,_)\n",
    "    epoch_level_mae.append(m[-1])\n",
    "    print('')\n",
    "    print('Epoch',_)\n",
    "    print('current loss : ',l[-1])\n",
    "    print('current mae : ',m[-1])\n",
    "    if (len(epoch_level_mae) >2 ) and epoch_level_mae[-1] - epoch_level_mae[-2] < 0:\n",
    "        optimiser.param_groups[0]['lr'] = optimiser.param_groups[0]['lr']/10\n",
    "        print('Optimiser learning rate reduced to '+str(optimiser.param_groups[0]['lr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cnn_mod.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
