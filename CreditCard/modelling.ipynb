{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import src\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/creditcard.csv'\n",
    "source = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling Plan\n",
    "\n",
    "0. Set up a testing framework\n",
    "1. Set up a benchmark model on the data as it stands (Logistic Regression)\n",
    "2. Apply preprocessings, namely normalisation, over/under sampling, outlier detection, and reapply to benchmark model.\n",
    "3. Apply a range of models, including a RandomForest, NaiveBayes, XGBoost.\n",
    "4. Concluding analysis\n",
    "\n",
    "Disclaimer : This is the first time I have learnt about the imblearn library, so my main focus will be to understand its use rather than actually gaining an optimal area-under-precisison-recall curve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Testing Framework\n",
    "\n",
    "In the soruce scripts `src/tests.py`, the function `panel_of_tests(y_pred, y_observed)` conducts the folloing tests: \n",
    "\n",
    "* Precision\n",
    "* Recall\n",
    "* F1\n",
    "* AUPRC (Average recall precision (Area under Recall Precision curve))\n",
    "* Accuracy\n",
    "* Balanced Accuracy\n",
    "* ROC_AUC\n",
    "\n",
    "Given the imbalanced dataset, we are most interested in AUPRC, but we can use the remaining metrics as a guide. Accuracy is there for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'Precision': 0.25,\n 'Recall': 0.5,\n 'F1': 0.3333333333333333,\n 'AUPRC': 0.20833333333333331,\n 'Accuracy': 0.6,\n 'Balanced Accuracy': 0.5625,\n 'ROC_AUC': 0.5625}"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# an as example, demonstrate the testing panel function\n",
    "\n",
    "y_obs = np.random.randint(0,2,10)\n",
    "y_pred = np.random.randint(0,2,10)\n",
    "y_score = np.random.uniform(0,1,10)\n",
    "\n",
    "src.panel_of_tests(y_pred, y_obs, y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set up benchmark model\n",
    "\n",
    "In this secton we set up a very simply logistic regression model, via cross validation.\n",
    "\n",
    "The code that performs the model implementation is found in `src/models.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for training\n",
    "\n",
    "def prepare_data(data):\n",
    "    Y = data['Class']\n",
    "    X = data.drop(['Class'], axis = 1)\n",
    "\n",
    "    X = X.values\n",
    "    Y = Y.values\n",
    "    return X, Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " Fold [5/5]"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Precision    Recall        F1     AUPRC  Accuracy Balanced Accuracy  \\\n0     0.846154  0.666667  0.745763  0.669032   0.99921          0.833228   \n1     0.847222  0.616162   0.71345   0.63178   0.99914          0.807984   \n2     0.859155  0.622449  0.721893  0.668897  0.999175          0.811137   \n3     0.837838  0.632653   0.72093  0.647575  0.999157          0.816221   \n4     0.828571  0.591837  0.690476  0.639212  0.999087          0.795813   \nmean  0.843788  0.625953  0.718503  0.651299  0.999154          0.812876   \n\n       ROC_AUC  \n0     0.833228  \n1     0.807984  \n2     0.811137  \n3     0.816221  \n4     0.795813  \nmean  0.812876  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>AUPRC</th>\n      <th>Accuracy</th>\n      <th>Balanced Accuracy</th>\n      <th>ROC_AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.846154</td>\n      <td>0.666667</td>\n      <td>0.745763</td>\n      <td>0.669032</td>\n      <td>0.99921</td>\n      <td>0.833228</td>\n      <td>0.833228</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.847222</td>\n      <td>0.616162</td>\n      <td>0.71345</td>\n      <td>0.63178</td>\n      <td>0.99914</td>\n      <td>0.807984</td>\n      <td>0.807984</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.859155</td>\n      <td>0.622449</td>\n      <td>0.721893</td>\n      <td>0.668897</td>\n      <td>0.999175</td>\n      <td>0.811137</td>\n      <td>0.811137</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.837838</td>\n      <td>0.632653</td>\n      <td>0.72093</td>\n      <td>0.647575</td>\n      <td>0.999157</td>\n      <td>0.816221</td>\n      <td>0.816221</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.828571</td>\n      <td>0.591837</td>\n      <td>0.690476</td>\n      <td>0.639212</td>\n      <td>0.999087</td>\n      <td>0.795813</td>\n      <td>0.795813</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.843788</td>\n      <td>0.625953</td>\n      <td>0.718503</td>\n      <td>0.651299</td>\n      <td>0.999154</td>\n      <td>0.812876</td>\n      <td>0.812876</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# training data via cross validation\n",
    "\n",
    "data = source.copy()\n",
    "X,Y = prepare_data(data)\n",
    "\n",
    "cv_model = src.cv_modelling(X,Y, folds = 5,sampling_function = None, outlier_function = None)\n",
    "model = 'logistic'\n",
    "C = '1'\n",
    "model_string = ' '.join([model,C])\n",
    "model_performancemodel_performance, models = cv_model.fit(model_string)\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above provides the initial benchmark model - the interest of real interest is the AUPRC which is the area under the precision/recall curve. It is worth noting that the precision is consistently greater than recall, this is a result of the target imbalance and can be seen to come as follows, recall the formulae:\n",
    "\n",
    "\\begin{equation}\\begin{aligned} \\text{Precesion} = \\frac{\\text{TP}}{\\text{TP}+\\text{FP}},\\\\ \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} \\end{aligned}.\\end{equation}\n",
    "\n",
    "Since, we have many more negative cases than positive, the model is more likely to misclassify positive (y=1) results as negative (y=0) than the other way around. This means that false negatives will tend to be relatively larger than false positives. This makes precision relatively larger then recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the value of the model coefficients to see the model importance of the features. This is since the logisitic model used above includes a lasso term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    FOLD_0  FOLD_1  FOLD_2  FOLD_3  FOLD_4\n0       V3      V3      V3      V3      V3\n1      V15     V15     V15      V7      V7\n2      V25      V7      V7     V15     V15\n3      V14     V25     V25     V25     V25\n4       V7     V14     V14     V14     V14\n5      V22     V22     V22     V22     V22\n6      V21      V9      V9     V11     V21\n7      V11     V11     V11      V9     V11\n8      V17     V21     V21     V21      V9\n9       V9     V17      V8     V13     V17\n10      V8     V13     V17     V17     V13\n11      V2      V8     V13      V8     V10\n12     V13     V10      V2      V2      V8\n13     V16      V1      V1     V16      V2\n14     V10     V16     V10      V1     V16\n15      V4      V2     V16     V10      V1\n16     V20     V20     V20      V4     V20\n17      V1      V4      V4     V12      V4\n18     V27     V26     V26     V20     V18\n19     V12      V5      V5     V26      V6\n20     V26     V18     V12      V5     V12\n21      V5     V12     V27     V27     V26\n22     V23     V27     V18     V28     V27\n23     V18      V6     V28     V18      V5\n24     V24     V28      V6      V6     V28\n25     V19     V24     V23     V23     V23\n26      V6     V23     V24     V24     V24\n27     V28  Amount     V19  Amount  Amount\n28  Amount     V19  Amount     V19     V19\n29    Time    Time    Time    Time    Time",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FOLD_0</th>\n      <th>FOLD_1</th>\n      <th>FOLD_2</th>\n      <th>FOLD_3</th>\n      <th>FOLD_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>V3</td>\n      <td>V3</td>\n      <td>V3</td>\n      <td>V3</td>\n      <td>V3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>V15</td>\n      <td>V15</td>\n      <td>V15</td>\n      <td>V7</td>\n      <td>V7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>V25</td>\n      <td>V7</td>\n      <td>V7</td>\n      <td>V15</td>\n      <td>V15</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>V14</td>\n      <td>V25</td>\n      <td>V25</td>\n      <td>V25</td>\n      <td>V25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>V7</td>\n      <td>V14</td>\n      <td>V14</td>\n      <td>V14</td>\n      <td>V14</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>V22</td>\n      <td>V22</td>\n      <td>V22</td>\n      <td>V22</td>\n      <td>V22</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>V21</td>\n      <td>V9</td>\n      <td>V9</td>\n      <td>V11</td>\n      <td>V21</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>V11</td>\n      <td>V11</td>\n      <td>V11</td>\n      <td>V9</td>\n      <td>V11</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>V17</td>\n      <td>V21</td>\n      <td>V21</td>\n      <td>V21</td>\n      <td>V9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>V9</td>\n      <td>V17</td>\n      <td>V8</td>\n      <td>V13</td>\n      <td>V17</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>V8</td>\n      <td>V13</td>\n      <td>V17</td>\n      <td>V17</td>\n      <td>V13</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>V2</td>\n      <td>V8</td>\n      <td>V13</td>\n      <td>V8</td>\n      <td>V10</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>V13</td>\n      <td>V10</td>\n      <td>V2</td>\n      <td>V2</td>\n      <td>V8</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>V16</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V16</td>\n      <td>V2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>V10</td>\n      <td>V16</td>\n      <td>V10</td>\n      <td>V1</td>\n      <td>V16</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>V4</td>\n      <td>V2</td>\n      <td>V16</td>\n      <td>V10</td>\n      <td>V1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>V20</td>\n      <td>V20</td>\n      <td>V20</td>\n      <td>V4</td>\n      <td>V20</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>V1</td>\n      <td>V4</td>\n      <td>V4</td>\n      <td>V12</td>\n      <td>V4</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>V27</td>\n      <td>V26</td>\n      <td>V26</td>\n      <td>V20</td>\n      <td>V18</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>V12</td>\n      <td>V5</td>\n      <td>V5</td>\n      <td>V26</td>\n      <td>V6</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>V26</td>\n      <td>V18</td>\n      <td>V12</td>\n      <td>V5</td>\n      <td>V12</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>V5</td>\n      <td>V12</td>\n      <td>V27</td>\n      <td>V27</td>\n      <td>V26</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>V23</td>\n      <td>V27</td>\n      <td>V18</td>\n      <td>V28</td>\n      <td>V27</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>V18</td>\n      <td>V6</td>\n      <td>V28</td>\n      <td>V18</td>\n      <td>V5</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>V24</td>\n      <td>V28</td>\n      <td>V6</td>\n      <td>V6</td>\n      <td>V28</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>V19</td>\n      <td>V24</td>\n      <td>V23</td>\n      <td>V23</td>\n      <td>V23</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>V6</td>\n      <td>V23</td>\n      <td>V24</td>\n      <td>V24</td>\n      <td>V24</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>V28</td>\n      <td>Amount</td>\n      <td>V19</td>\n      <td>Amount</td>\n      <td>Amount</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Amount</td>\n      <td>V19</td>\n      <td>Amount</td>\n      <td>V19</td>\n      <td>V19</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Time</td>\n      <td>Time</td>\n      <td>Time</td>\n      <td>Time</td>\n      <td>Time</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# feature importances\n",
    "Numerical = ['Time','V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
    "       \n",
    "def extract_importance(columns, feature_importances):\n",
    "    idx = np.argsort(abs(feature_importances)).ravel()[::-1]\n",
    "    return np.array(columns)[idx]\n",
    "\n",
    "data = {'FOLD_' + str(i): extract_importance(Numerical, models[i].coef_) for i in range(0,5)}\n",
    "\n",
    "df = pd.DataFrame(data =data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Each fold found slightly different feature to be most important: we can find the intersection of the top 5. We can use a voting system amoung the folds to find the higher ranking features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['V3', 'V15', 'V15', 'V25', 'V14']"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "top = 5\n",
    "[df.iloc[i].mode().values[0] for i in range(0,len(Numerical))][:top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Apply preprocessing, sampling techniques and outlier detection\n",
    "In this subsection, we shall apply some basic preprocessing together with various sampling techniques, and outlier windowing to see how this changes the benchmark model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.i : Normalise\n",
    "Normalise the data with respect the median and the IQR, and check the benchmark model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def normalise(data):\n",
    "    rs = RobustScaler()\n",
    "    data[['Time','Amount']] = rs.fit_transform(data[['Time','Amount']].values)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " Fold [5/5]"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Precision    Recall        F1     AUPRC  Accuracy Balanced Accuracy  \\\n0     0.846154  0.666667  0.745763  0.669032   0.99921          0.833228   \n1     0.847222  0.616162   0.71345   0.63178   0.99914          0.807984   \n2     0.859155  0.622449  0.721893  0.668897  0.999175          0.811137   \n3     0.837838  0.632653   0.72093  0.647575  0.999157          0.816221   \n4     0.828571  0.591837  0.690476  0.639212  0.999087          0.795813   \nmean  0.843788  0.625953  0.718503  0.651299  0.999154          0.812876   \n\n       ROC_AUC  \n0     0.833228  \n1     0.807984  \n2     0.811137  \n3     0.816221  \n4     0.795813  \nmean  0.812876  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>AUPRC</th>\n      <th>Accuracy</th>\n      <th>Balanced Accuracy</th>\n      <th>ROC_AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.846154</td>\n      <td>0.666667</td>\n      <td>0.745763</td>\n      <td>0.669032</td>\n      <td>0.99921</td>\n      <td>0.833228</td>\n      <td>0.833228</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.847222</td>\n      <td>0.616162</td>\n      <td>0.71345</td>\n      <td>0.63178</td>\n      <td>0.99914</td>\n      <td>0.807984</td>\n      <td>0.807984</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.859155</td>\n      <td>0.622449</td>\n      <td>0.721893</td>\n      <td>0.668897</td>\n      <td>0.999175</td>\n      <td>0.811137</td>\n      <td>0.811137</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.837838</td>\n      <td>0.632653</td>\n      <td>0.72093</td>\n      <td>0.647575</td>\n      <td>0.999157</td>\n      <td>0.816221</td>\n      <td>0.816221</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.828571</td>\n      <td>0.591837</td>\n      <td>0.690476</td>\n      <td>0.639212</td>\n      <td>0.999087</td>\n      <td>0.795813</td>\n      <td>0.795813</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.843788</td>\n      <td>0.625953</td>\n      <td>0.718503</td>\n      <td>0.651299</td>\n      <td>0.999154</td>\n      <td>0.812876</td>\n      <td>0.812876</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "\n",
    "data = source.copy()\n",
    "data = normalise(data)\n",
    "X,Y = prepare_data(data)\n",
    "\n",
    "\n",
    "\n",
    "cv_model = src.cv_modelling(X,Y, folds = 5,sampling_function = None, outlier_function = None)\n",
    "model = 'logistic'\n",
    "C = '1'\n",
    "model_string = ' '.join([model,C])\n",
    "model_performancemodel_performance, models = cv_model.fit(model_string)\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the mean AUPRC has improved, thus this is the new accepted benchmark.\n",
    "\n",
    "#### 2.ii Windowing\n",
    "\n",
    "In this subsection, we consider windowing to remove any outliers - filtering for data above the 1% and below the 99% percentile per feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " Fold [5/5]"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Precision    Recall        F1      AUPRC  Accuracy Balanced Accuracy  \\\n0     0.195122  0.161616  0.176796  0.0624945  0.997384          0.580228   \n1        0.375  0.181818  0.244898   0.153259  0.998051          0.590645   \n2     0.240506  0.193878  0.214689  0.0994752   0.99756          0.596411   \n3     0.410714  0.234694  0.298701   0.184775  0.998104          0.617057   \n4     0.240964  0.204082  0.220994  0.0930842  0.997525          0.601487   \nmean  0.292461  0.195217  0.231216   0.118618  0.997725          0.597166   \n\n       ROC_AUC  \n0     0.580228  \n1     0.590645  \n2     0.596411  \n3     0.617057  \n4     0.601487  \nmean  0.597166  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>AUPRC</th>\n      <th>Accuracy</th>\n      <th>Balanced Accuracy</th>\n      <th>ROC_AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.195122</td>\n      <td>0.161616</td>\n      <td>0.176796</td>\n      <td>0.0624945</td>\n      <td>0.997384</td>\n      <td>0.580228</td>\n      <td>0.580228</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.375</td>\n      <td>0.181818</td>\n      <td>0.244898</td>\n      <td>0.153259</td>\n      <td>0.998051</td>\n      <td>0.590645</td>\n      <td>0.590645</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.240506</td>\n      <td>0.193878</td>\n      <td>0.214689</td>\n      <td>0.0994752</td>\n      <td>0.99756</td>\n      <td>0.596411</td>\n      <td>0.596411</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.410714</td>\n      <td>0.234694</td>\n      <td>0.298701</td>\n      <td>0.184775</td>\n      <td>0.998104</td>\n      <td>0.617057</td>\n      <td>0.617057</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.240964</td>\n      <td>0.204082</td>\n      <td>0.220994</td>\n      <td>0.0930842</td>\n      <td>0.997525</td>\n      <td>0.601487</td>\n      <td>0.601487</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.292461</td>\n      <td>0.195217</td>\n      <td>0.231216</td>\n      <td>0.118618</td>\n      <td>0.997725</td>\n      <td>0.597166</td>\n      <td>0.597166</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "data = source.copy()\n",
    "data = normalise(data)\n",
    "X,Y = prepare_data(data)\n",
    "\n",
    "outlier_function = src.delete_outliers\n",
    "\n",
    "cv_model = src.cv_modelling(X,Y, folds = 5,sampling_function = None, outlier_function = outlier_function)\n",
    "model = 'logistic'\n",
    "C = '1'\n",
    "model_string = ' '.join([model,C])\n",
    "model_performance, models = cv_model.fit(model_string)\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to be a strong decrease in performance.\n",
    "\n",
    "#### 2.ii Undersampling\n",
    "\n",
    "In this subsection, we consider random undersampling. This is where we make the number of datapoints associated to the majority target class the same as the number of minority targets by simply randomly sampling the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " Fold [5/5]"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      Precision    Recall         F1     AUPRC  Accuracy Balanced Accuracy  \\\n0     0.0412002  0.929293  0.0789022  0.714616  0.962291          0.945821   \n1     0.0530077   0.89899   0.100112  0.698152  0.971911          0.935514   \n2     0.0493827  0.897959   0.093617  0.488979  0.970085          0.934084   \n3     0.0465473  0.928571  0.0886508  0.737661  0.967153          0.947895   \n4      0.041919  0.918367  0.0801782  0.678554  0.963747          0.941096   \nmean  0.0464114  0.914636  0.0882921  0.663592  0.967037          0.940882   \n\n       ROC_AUC  \n0     0.945821  \n1     0.935514  \n2     0.934084  \n3     0.947895  \n4     0.941096  \nmean  0.940882  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>AUPRC</th>\n      <th>Accuracy</th>\n      <th>Balanced Accuracy</th>\n      <th>ROC_AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0412002</td>\n      <td>0.929293</td>\n      <td>0.0789022</td>\n      <td>0.714616</td>\n      <td>0.962291</td>\n      <td>0.945821</td>\n      <td>0.945821</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0530077</td>\n      <td>0.89899</td>\n      <td>0.100112</td>\n      <td>0.698152</td>\n      <td>0.971911</td>\n      <td>0.935514</td>\n      <td>0.935514</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0493827</td>\n      <td>0.897959</td>\n      <td>0.093617</td>\n      <td>0.488979</td>\n      <td>0.970085</td>\n      <td>0.934084</td>\n      <td>0.934084</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0465473</td>\n      <td>0.928571</td>\n      <td>0.0886508</td>\n      <td>0.737661</td>\n      <td>0.967153</td>\n      <td>0.947895</td>\n      <td>0.947895</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.041919</td>\n      <td>0.918367</td>\n      <td>0.0801782</td>\n      <td>0.678554</td>\n      <td>0.963747</td>\n      <td>0.941096</td>\n      <td>0.941096</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.0464114</td>\n      <td>0.914636</td>\n      <td>0.0882921</td>\n      <td>0.663592</td>\n      <td>0.967037</td>\n      <td>0.940882</td>\n      <td>0.940882</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# undersampling the data\n",
    "under = RandomUnderSampler()\n",
    "\n",
    "data = source.copy()\n",
    "data = normalise(data)\n",
    "X,Y = prepare_data(data)\n",
    "\n",
    "sampling_function = under.fit_resample\n",
    "\n",
    "cv_model = src.cv_modelling(X,Y,folds = 5, sampling_function = sampling_function, outlier_function = None)\n",
    "model = 'logistic'\n",
    "C = '1'\n",
    "model_string = ' '.join([model,C])\n",
    "model_performance, models = cv_model.fit(model_string)\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This actually slightly beats our very orginal benchmark model, whilst training very quickly since there is far less data.\n",
    "\n",
    "The main problem with this approach is that it undergoes a very heavily information loss, from which we really cannot guarantee a clear out of sample generalisation. \n",
    "\n",
    "#### 2.iii Over sampling\n",
    "\n",
    "We now consider oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " Fold [5/5]"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      Precision    Recall        F1     AUPRC  Accuracy Balanced Accuracy  \\\n0     0.0602981   0.89899  0.113016   0.72682  0.975475          0.937299   \n1     0.0649057  0.868687  0.120787  0.660223   0.97802          0.923449   \n2     0.0612903  0.969388  0.115291  0.772968  0.974404            0.9719   \n3     0.0566625  0.928571  0.106808  0.753825   0.97328          0.950964   \n4     0.0587828  0.867347  0.110104  0.743365  0.975878          0.921706   \nmean  0.0603879  0.906597  0.113201   0.73144  0.975411          0.941064   \n\n       ROC_AUC  \n0     0.937299  \n1     0.923449  \n2       0.9719  \n3     0.950964  \n4     0.921706  \nmean  0.941064  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>AUPRC</th>\n      <th>Accuracy</th>\n      <th>Balanced Accuracy</th>\n      <th>ROC_AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0602981</td>\n      <td>0.89899</td>\n      <td>0.113016</td>\n      <td>0.72682</td>\n      <td>0.975475</td>\n      <td>0.937299</td>\n      <td>0.937299</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0649057</td>\n      <td>0.868687</td>\n      <td>0.120787</td>\n      <td>0.660223</td>\n      <td>0.97802</td>\n      <td>0.923449</td>\n      <td>0.923449</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0612903</td>\n      <td>0.969388</td>\n      <td>0.115291</td>\n      <td>0.772968</td>\n      <td>0.974404</td>\n      <td>0.9719</td>\n      <td>0.9719</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0566625</td>\n      <td>0.928571</td>\n      <td>0.106808</td>\n      <td>0.753825</td>\n      <td>0.97328</td>\n      <td>0.950964</td>\n      <td>0.950964</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0587828</td>\n      <td>0.867347</td>\n      <td>0.110104</td>\n      <td>0.743365</td>\n      <td>0.975878</td>\n      <td>0.921706</td>\n      <td>0.921706</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.0603879</td>\n      <td>0.906597</td>\n      <td>0.113201</td>\n      <td>0.73144</td>\n      <td>0.975411</td>\n      <td>0.941064</td>\n      <td>0.941064</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "over = SMOTE()\n",
    "\n",
    "data = source.copy()\n",
    "data = normalise(data)\n",
    "X,Y = prepare_data(data)\n",
    "\n",
    "sampling_function = over.fit_resample\n",
    "\n",
    "cv_model = src.cv_modelling(X,Y,folds = 5, sampling_function = sampling_function, outlier_function = None)\n",
    "model = 'logistic'\n",
    "C = '1'\n",
    "model_string = ' '.join([model,C])\n",
    "model_performance, models = cv_model.fit(model_string)\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.iv Combination of over/under sampling\n",
    "\n",
    "It is also posible to consider a combination of oversampling and then performing a random undersampling, as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resample(object):\n",
    "    def __init__(self, under_sample_stratergy, over_sample_strategy):\n",
    "        self.under_sample = under_sample_stratergy\n",
    "        self.over_sample = over_sample_strategy\n",
    "        \n",
    "        \"\"\"\n",
    "        Stratergy is such that count(y==1)/count(y == 0) = stratergy\n",
    "        \"\"\"\n",
    "    \n",
    "    def fit_resample(self, XX,YY):\n",
    "        under = RandomUnderSampler(sampling_strategy=self.under_sample)\n",
    "        over = SMOTE(sampling_strategy=self.over_sample)\n",
    "\n",
    "        XX,YY = over.fit_resample(XX,YY)\n",
    "        XX,YY = under.fit_resample(XX,YY)\n",
    "        return XX,YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " Fold [5/5]"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Precision    Recall        F1     AUPRC  Accuracy Balanced Accuracy  \\\n0     0.222506  0.878788  0.355102  0.779062  0.994452          0.936721   \n1     0.235294  0.888889  0.372093  0.781648  0.994786           0.94193   \n2     0.194064  0.867347  0.317164  0.758888  0.993575           0.93057   \n3     0.218837  0.806122  0.344227  0.683899  0.994716          0.900582   \n4     0.241096  0.897959   0.38013   0.72428  0.994961          0.946544   \nmean  0.222359  0.867821  0.353743  0.745556  0.994498          0.931269   \n\n       ROC_AUC  \n0     0.936721  \n1      0.94193  \n2      0.93057  \n3     0.900582  \n4     0.946544  \nmean  0.931269  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>AUPRC</th>\n      <th>Accuracy</th>\n      <th>Balanced Accuracy</th>\n      <th>ROC_AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.222506</td>\n      <td>0.878788</td>\n      <td>0.355102</td>\n      <td>0.779062</td>\n      <td>0.994452</td>\n      <td>0.936721</td>\n      <td>0.936721</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.235294</td>\n      <td>0.888889</td>\n      <td>0.372093</td>\n      <td>0.781648</td>\n      <td>0.994786</td>\n      <td>0.94193</td>\n      <td>0.94193</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.194064</td>\n      <td>0.867347</td>\n      <td>0.317164</td>\n      <td>0.758888</td>\n      <td>0.993575</td>\n      <td>0.93057</td>\n      <td>0.93057</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.218837</td>\n      <td>0.806122</td>\n      <td>0.344227</td>\n      <td>0.683899</td>\n      <td>0.994716</td>\n      <td>0.900582</td>\n      <td>0.900582</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.241096</td>\n      <td>0.897959</td>\n      <td>0.38013</td>\n      <td>0.72428</td>\n      <td>0.994961</td>\n      <td>0.946544</td>\n      <td>0.946544</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.222359</td>\n      <td>0.867821</td>\n      <td>0.353743</td>\n      <td>0.745556</td>\n      <td>0.994498</td>\n      <td>0.931269</td>\n      <td>0.931269</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "over_under = resample(0.2,0.1)\n",
    "\n",
    "data = source.copy()\n",
    "data = normalise(data)\n",
    "X,Y = prepare_data(data)\n",
    "\n",
    "sampling_function = over_under.fit_resample\n",
    "\n",
    "cv_model = src.cv_modelling(X,Y,folds = 5, sampling_function = sampling_function, outlier_function = None)\n",
    "model = 'logistic'\n",
    "C = '1'\n",
    "model_string = ' '.join([model,C])\n",
    "model_performance, models = cv_model.fit(model_string)\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Grid search over many models\n",
    "\n",
    "We now consider LogisticRegression, RandomForest, NaiveBayes, and XGBoost. We run these models over different sampling strategies and whether outlier removal occurs or not. To do this, we introduce a new function which allows us to amalgamate over and under sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resample(object):\n",
    "    def __init__(self, under_sample_stratergy, over_sample_strategy):\n",
    "        self.under_sample = under_sample_stratergy\n",
    "        self.over_sample = over_sample_strategy\n",
    "        \n",
    "        \"\"\"\n",
    "        Stratergy is such that count(y==1)/count(y == 0) = stratergy\n",
    "        \"\"\"\n",
    "    \n",
    "    def fit_resample(self, XX,YY):\n",
    "        if np.isnan(self.under_sample) and np.isnan(self.over_sample):\n",
    "            return XX,YY\n",
    "        elif not np.isnan(self.under_sample) and np.isnan(self.over_sample):\n",
    "            under = RandomUnderSampler(sampling_strategy=self.under_sample)\n",
    "            return under.fit_resample(XX,YY)\n",
    "        elif np.isnan(self.under_sample) and not np.isnan(self.over_sample):\n",
    "            over = SMOTE(sampling_strategy=self.over_sample)\n",
    "            return over.fit_resample(XX,YY)\n",
    "        else:\n",
    "            \n",
    "            under = RandomUnderSampler(sampling_strategy=self.under_sample)\n",
    "            over = SMOTE(sampling_strategy=self.over_sample)\n",
    "\n",
    "            XX,YY = over.fit_resample(XX,YY)\n",
    "            XX,YY = under.fit_resample(XX,YY)\n",
    "            return XX,YY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up a results table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_results_df():\n",
    "    single_sampling_grid = np.linspace(0.2,1.0,4)\n",
    "    over_under_grid = []\n",
    "    for para_i in range(0,len(single_sampling_grid)):\n",
    "        for para_j in range(para_i, len(single_sampling_grid)):\n",
    "            over_under_grid.append((single_sampling_grid[para_i],single_sampling_grid[para_j]))\n",
    "    over_under_grid = np.array(over_under_grid)\n",
    "\n",
    "    results_df = pd.DataFrame(columns = ['OVER','UNDER','OUTLIER_REMOVAL','Precision','Recall', 'F1','AUPRC',  'Accuracy','Balanced Accuracy','ROC_AUC'], \\\n",
    "                      index = np.arange(1+2*len(single_sampling_grid) + len(over_under_grid)))\n",
    "\n",
    "    results_df['OVER'][:len(single_sampling_grid)] = single_sampling_grid\n",
    "    results_df['UNDER'][len(single_sampling_grid):2*len(single_sampling_grid)] = single_sampling_grid\n",
    "    results_df['OVER'][2*len(single_sampling_grid):-1] = over_under_grid[:,0]\n",
    "    results_df['UNDER'][2*len(single_sampling_grid):-1] = over_under_grid[:,1]\n",
    "\n",
    "    with_outliers = results_df.copy()\n",
    "    without_outliers = results_df.copy()\n",
    "\n",
    "    without_outliers['OUTLIER_REMOVAL'] = 1\n",
    "    with_outliers['OUTLIER_REMOVAL'] = 0\n",
    "\n",
    "    results = pd.concat([with_outliers, without_outliers],0)\n",
    "    results = results.reset_index()\n",
    "    del results['index']\n",
    "\n",
    "\n",
    "    metrics = ['Precision','Recall', 'F1','AUPRC', 'Accuracy','Balanced Accuracy','ROC_AUC']\n",
    "    \n",
    "    return results, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's see what the results table shows. Each row in the results table is a configuration to be considered for the grid search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OVER                 0.2\nUNDER                NaN\nOUTLIER_REMOVAL        0\nPrecision            NaN\nRecall               NaN\nF1                   NaN\nAUPRC                NaN\nAccuracy             NaN\nBalanced Accuracy    NaN\nROC_AUC              NaN\nName: 0, dtype: object"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "results, metrics = set_up_results_df()\n",
    "results.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_specification(spec, model_string):\n",
    "    \"\"\"\n",
    "    Runs the model against the specification determined by set_up_results_df().\n",
    "    \"\"\"\n",
    "    sampler = resample(spec['UNDER'],spec['OVER'])\n",
    "    if bool(spec['OUTLIER_REMOVAL']):\n",
    "        cv_model = cv_modelling(X,Y,folds = 5, sampling_function = sampler.fit_resample,\\\n",
    "                                                    outlier_function = delete_outliers)\n",
    "    else:\n",
    "        cv_model = cv_modelling(X,Y,folds = 5, sampling_function = sampler.fit_resample,\\\n",
    "                                                    outlier_function = None)\n",
    "    model_performance, models = cv_model.fit(model_string, verbose = False)\n",
    "    return model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.i Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, metrics = set_up_results_df()\n",
    "n_configs, _ = results.shape\n",
    "\n",
    "model_string = 'logistic 1'\n",
    "for i in range(n_configs):\n",
    "    print('\\r', 'CONFIGURATIONS [{}/{}]'.format(i+1,n_configs), end='')\n",
    "    spec = results.iloc[i]\n",
    "    model_performance = run_specification(spec,model_string)\n",
    "    results.at[i,metrics] = list(map(lambda x: model_performance.loc['mean'][x],metrics))\n",
    "results.to_csv('results/Logistic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.ii Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, metrics = set_up_results_df()\n",
    "n_configs, _ = results.shape\n",
    "\n",
    "model_string = 'randomforest 20 4'\n",
    "for i in range(n_configs):\n",
    "    print('\\r', 'CONFIGURATIONS [{}/{}]'.format(i+1,n_configs), end='')\n",
    "    spec = results.iloc[i]\n",
    "    model_performance = run_specification(spec,model_string)\n",
    "    results.at[i,metrics] = list(map(lambda x: model_performance.loc['mean'][x],metrics))\n",
    "results.to_csv('results/RandomForest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.iii NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, metrics = set_up_results_df()\n",
    "n_configs, _ = results.shape\n",
    "\n",
    "model_string = 'NBGaussian'\n",
    "for i in range(n_configs):\n",
    "    print('\\r', 'CONFIGURATIONS [{}/{}]'.format(i+1,n_configs), end='')\n",
    "    spec = results.iloc[i]\n",
    "    model_performance = run_specification(spec,model_string)\n",
    "    results.at[i,metrics] = list(map(lambda x: model_performance.loc['mean'][x],metrics))\n",
    "results.to_csv('results/NaiveBayes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.iv XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, metrics = set_up_results_df()\n",
    "n_configs, _ = results.shape\n",
    "\n",
    "model_string = 'xgboost 20 4'\n",
    "for i in range(n_configs):\n",
    "    print('\\r', 'CONFIGURATIONS [{}/{}]'.format(i+1,n_configs), end='')\n",
    "    spec = results.iloc[i]\n",
    "    model_performance = run_specification(spec,model_string)\n",
    "    results.at[i,metrics] = list(map(lambda x: model_performance.loc['mean'][x],metrics))\n",
    "results.to_csv('results/XGBoost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model analysis\n",
    "\n",
    "Now that we have collected all the results to the `results` folder, we can seek out the best configurations from the models studied so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_result = 'results/Logistic.csv'\n",
    "naivebayes_result = 'results/NaiveBayes.csv'\n",
    "randomforest_results = 'results/RandomForest.csv'\n",
    "xgboost_results = 'results/XGBoost.csv'\n",
    "\n",
    "logistic_result = pd.read_csv(logistic_result, index_col = 0)\n",
    "naivebayes_result = pd.read_csv(naivebayes_result, index_col = 0)\n",
    "randomforest_results = pd.read_csv(randomforest_results, index_col = 0)\n",
    "xgboost_results = pd.read_csv(xgboost_results, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OVER                      NaN\nUNDER                     NaN\nOUTLIER_REMOVAL      0.000000\nPrecision            0.871650\nRecall               0.626036\nF1                   0.727581\nAUPRC                0.760470\nAccuracy             0.999192\nBalanced Accuracy    0.812937\nROC_AUC              0.812937\nName: 18, dtype: float64"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "log_idx = logistic_result['AUPRC'].argmax()\n",
    "logistic_result.iloc[log_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OVER                      NaN\nUNDER                     NaN\nOUTLIER_REMOVAL      1.000000\nPrecision            0.057466\nRecall               0.412162\nF1                   0.100321\nAUPRC                0.140106\nAccuracy             0.986893\nBalanced Accuracy    0.700025\nROC_AUC              0.700025\nName: 37, dtype: float64"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "nb_idx = naivebayes_result['AUPRC'].argmax()\n",
    "naivebayes_result.iloc[nb_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OVER                      NaN\nUNDER                     NaN\nOUTLIER_REMOVAL      0.000000\nPrecision            0.911496\nRecall               0.678932\nF1                   0.777634\nAUPRC                0.804665\nAccuracy             0.999329\nBalanced Accuracy    0.839408\nROC_AUC              0.839408\nName: 18, dtype: float64"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "rf_idx = randomforest_results['AUPRC'].argmax()\n",
    "randomforest_results.iloc[rf_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OVER                      NaN\nUNDER                     NaN\nOUTLIER_REMOVAL      0.000000\nPrecision            0.923132\nRecall               0.792641\nF1                   0.852086\nAUPRC                0.815827\nAccuracy             0.999526\nBalanced Accuracy    0.896262\nROC_AUC              0.896262\nName: 18, dtype: float64"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "xg_idx = xgboost_results['AUPRC'].argmax()\n",
    "xgboost_results.iloc[xg_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitmlenvconda9f54039d931e4029adcffd4ea832f0f0",
   "display_name": "Python 3.6.9 64-bit ('ml_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}